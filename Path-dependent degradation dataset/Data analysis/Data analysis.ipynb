{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold, GroupShuffleSplit, GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.utils.validation import check_array, check_random_state, _deprecate_positional_args\n",
    "from sklearn.model_selection._split import _BaseKFold, _RepeatedSplits\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device to GPU if available\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cycle vs capacity retention\n",
    "\n",
    "file_path = \"capacity list.xlsx\"\n",
    "data = pd.read_excel(file_path)\n",
    "cycle_numbers = data.columns[2:].astype(int)\n",
    "\n",
    "last_cycle_values = data.iloc[:, -1].values # set colors based on final capacity\n",
    "norm = plt.Normalize(vmin=last_cycle_values.min(), vmax=last_cycle_values.max())\n",
    "cmap = plt.get_cmap('viridis').reversed()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "y_min, y_max = 2.4, 3.25\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    y = row[2:].values  \n",
    "    x_new = np.linspace(cycle_numbers.min(), cycle_numbers.max(), 300)\n",
    "    spline = make_interp_spline(cycle_numbers, y, k=3)\n",
    "    y_smooth = spline(x_new)    \n",
    "    cell_color = cmap(norm(row.iloc[-2]))\n",
    "    ax.plot(x_new, y_smooth, color=cell_color, linewidth=1.5)\n",
    "    ax.scatter(cycle_numbers, y, color=cell_color, s=25, marker='o', zorder=3)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "cbar = fig.colorbar(sm, ax=ax, fraction=0.03, pad=0.04)\n",
    "cbar.set_label('Capacity (Ah)')\n",
    "ax.set_ylim([y_min, y_max])\n",
    "ax.set_xlabel('Cycle Number')\n",
    "ax.set_ylabel('Capacity (Ah)')\n",
    "ax.set_title('Cycle Number vs Capacity for Each Cell')\n",
    "ax.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future degradation path prediction\n",
    "\n",
    "# input data\n",
    "diagcap_final = current_health_state('diagnosis', 'capacity list.xlsx')\n",
    "sequence = torch.tensor(pd.read_excel('sequence list_index.xlsx', header=None).values, dtype=torch.long)\n",
    "\n",
    "# Select mode\n",
    "mode = 'full' # 'full', 'diagnosis-only', 'sequence-only'\n",
    "\n",
    "if mode == 'diagnosis-only':\n",
    "    sequence = torch.zeros_like(sequence)\n",
    "elif mode == 'sequence-only':\n",
    "    diagcap_final = torch.zeros_like(diagcap_final)\n",
    "\n",
    "# target data\n",
    "futureVR = process_folder_futureDI('diagnosis')\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim_encoder = 11\n",
    "n_cat = 4\n",
    "hidden_dim = 64\n",
    "output_dim = 10\n",
    "lr = 0.0004\n",
    "batch_size = 6\n",
    "randomst = 0\n",
    "num_folds = 6\n",
    "num_encoder_fc_layers = 2\n",
    "num_gru_layers = 2\n",
    "num_decoder_fc_layers = 0  \n",
    "num_epochs = 10000\n",
    "early_stopping_patience = 1500\n",
    "groups = np.repeat(np.arange(24), 3).tolist()\n",
    "date = 241009\n",
    "refs = 2 # 'refs' specifies the number of points excluded from the last cycle point for model evaluation and can be extended up to a range(1,11).\n",
    "\n",
    "# Results folder \n",
    "result_folder = f'degradation path prediction_{mode}_{date}'\n",
    "if not os.path.exists(result_folder):\n",
    "    os.makedirs(result_folder)\n",
    "        \n",
    "# perform prediction\n",
    "train_and_evaluate(diagcap_final, sequence, futureVR, groups, num_folds, randomst, \n",
    "                       input_dim_encoder, hidden_dim, num_encoder_fc_layers, \n",
    "                       n_cat, num_gru_layers, num_decoder_fc_layers, \n",
    "                       output_dim, batch_size, lr, num_epochs, early_stopping_patience, \n",
    "                       result_folder, device, refs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# future capacity trajectory prediction\n",
    "\n",
    "capacity = torch.tensor(pd.read_excel('capacity list.xlsx').iloc[:, 3:].values, dtype=torch.float32)\n",
    "\n",
    "capacity_folder = 'capacity_per_fold'\n",
    "if not os.path.exists(capacity_folder):\n",
    "    os.makedirs(capacity_folder)\n",
    "    \n",
    "# Hyperparameters\n",
    "randomst = 0\n",
    "num_folds = 6\n",
    "groups = np.repeat(np.arange(24), 3).tolist()\n",
    "\n",
    "# future capacity for various forecast length and folds\n",
    "target_capacity(capacity, groups, num_folds, randomst, capacity_folder)\n",
    "\n",
    "#Unified regression model with true DI and capacity\n",
    "result_folder = f'degradation path prediction_{mode}_{date}'\n",
    "ref_true = 1\n",
    "n_true = 1\n",
    "n_folds = 6\n",
    "model = unified_regression(result_folder, capacity_folder, n_folds, n_true, ref_true)\n",
    "\n",
    "#Prediction using the unified regression model with predicted DI as input\n",
    "evaluate_predictions(result_folder, capacity_folder, model, n_folds=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis (observed vs predicted VR, capacity at n = 1)\n",
    "\n",
    "result_folder = f'degradation path prediction_{mode}_{date}'\n",
    "\n",
    "file_prefix = ['fold_1', 'fold_2', 'fold_3', 'fold_4', 'fold_5', 'fold_6']\n",
    "file_suffix_performance = 'seq2seq_avg_rmse_mape_results_n1_ref1.csv'\n",
    "file_paths = [os.path.join(result_folder, f\"{prefix}_{file_suffix_performance}\") for prefix in file_prefix]\n",
    "rmse_values = [pd.read_csv(f)['Best RMSE'].dropna().values for f in file_paths]\n",
    "mape_values = [pd.read_csv(f)['Best MAPE'].dropna().values for f in file_paths]\n",
    "average_rmse = round(sum(r.sum() for r in rmse_values) / sum(len(r) for r in rmse_values),6)\n",
    "average_mape = round(sum(m.sum() for m in mape_values) / sum(len(m) for m in mape_values),2)\n",
    "print(f'RMSE : {average_rmse}, MAPE : {average_mape} for future degradation path prediction')\n",
    "\n",
    "file_path = f'{result_folder}/fold_performance_pred_rf_n1_ref1.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "rmse_mean = round(df['RMSE'].mean(),6)\n",
    "mape_mean = round(df['MAPE'].mean(),2)\n",
    "print(f'RMSE : {rmse_mean}, MAPE : {mape_mean} for future capacity trajectory prediction')\n",
    "\n",
    "file_suffix_predictions = 'seq2seq_predictions_sheet_n1_ref1.xlsx'\n",
    "file_suffix_targets = 'seq2seq_targets_sheet_n1_ref1.xlsx'\n",
    "predictions = {}\n",
    "targets = {}\n",
    "for prefix in file_prefix:\n",
    "    predictions_file = os.path.join(result_folder, f\"{prefix}_{file_suffix_predictions}\")\n",
    "    targets_file = os.path.join(result_folder, f\"{prefix}_{file_suffix_targets}\")    \n",
    "    predictions[prefix] = pd.read_excel(predictions_file, sheet_name=None)\n",
    "    targets[prefix] = pd.read_excel(targets_file, sheet_name=None)\n",
    "\n",
    "soc_10_50_combined_targets = pd.DataFrame()\n",
    "soc_10_50_combined_predictions = pd.DataFrame()\n",
    "soc_60_100_combined_targets = pd.DataFrame()\n",
    "soc_60_100_combined_predictions = pd.DataFrame()\n",
    "\n",
    "for prefix in file_prefix:\n",
    "    for sheet_name in predictions[prefix]:\n",
    "        pred_df = predictions[prefix][sheet_name]\n",
    "        targ_df = targets[prefix][sheet_name]\n",
    "        soc_10_50_combined_targets = pd.concat([soc_10_50_combined_targets, targ_df.iloc[:, 5:10]], axis=0)\n",
    "        soc_10_50_combined_predictions = pd.concat([soc_10_50_combined_predictions, pred_df.iloc[:, 5:10]], axis=0)\n",
    "        soc_60_100_combined_targets = pd.concat([soc_60_100_combined_targets, targ_df.iloc[:, 0:5]], axis=0)\n",
    "        soc_60_100_combined_predictions = pd.concat([soc_60_100_combined_predictions, pred_df.iloc[:, 0:5]], axis=0)\n",
    "\n",
    "predicted_results_file = os.path.join(result_folder, \"predicted_results_pred_rf_n1_ref1.xlsx\")\n",
    "predicted_results = pd.read_excel(predicted_results_file, sheet_name=None)\n",
    "actual_combined = pd.DataFrame()\n",
    "predicted_combined = pd.DataFrame()\n",
    "\n",
    "for sheet_name in predicted_results:\n",
    "    sheet_df = predicted_results[sheet_name]\n",
    "    actual_combined = pd.concat([actual_combined, sheet_df['Actual']], axis=0)\n",
    "    predicted_combined = pd.concat([predicted_combined, sheet_df['Predicted']], axis=0)\n",
    "\n",
    "plt.figure(figsize=(18, 4))\n",
    "colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
    "\n",
    "# SOC 10~50 scatter plot\n",
    "plt.subplot(1, 3, 1) \n",
    "for i, color in enumerate(colors):\n",
    "    plt.scatter(soc_10_50_combined_targets.iloc[:, i], soc_10_50_combined_predictions.iloc[:, i], label=f'SOC {50 - i * 10}', c=color, alpha=0.6)\n",
    "plt.xlabel('Observed ΔVR (V)')\n",
    "plt.ylabel('Predicted ΔVR (V)')\n",
    "plt.xlim([0.02, 0.13])\n",
    "plt.ylim([0.02, 0.13])\n",
    "plt.plot([0.02, 0.13], [0.02, 0.13], 'k--', linewidth=2)\n",
    "plt.title('Target vs Predictions (SOC 10~50)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# SOC 60~100 scatter plot\n",
    "plt.subplot(1, 3, 2)  \n",
    "for i, color in enumerate(colors):\n",
    "    plt.scatter(soc_60_100_combined_targets.iloc[:, i], soc_60_100_combined_predictions.iloc[:, i], label=f'SOC {60 + i * 10}', c=color, alpha=0.6)\n",
    "plt.xlabel('Observed ΔVR (V)')\n",
    "plt.ylabel('Predicted ΔVR (V)')\n",
    "plt.xlim([-0.10, -0.02])\n",
    "plt.ylim([-0.10, -0.02])\n",
    "plt.plot([-0.10, -0.02], [-0.10, -0.02], 'k--', linewidth=2)\n",
    "plt.title('Target vs Predictions (SOC 60~100)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# capacity scatter plot\n",
    "plt.subplot(1, 3, 3) \n",
    "plt.scatter(actual_combined, predicted_combined, label='Actual vs Predicted', c='teal', alpha=0.6)\n",
    "plt.xlabel('Observed capacity (Ah)')\n",
    "plt.ylabel('Predicted capacity (Ah)')\n",
    "plt.xlim([2.4,3.25])\n",
    "plt.ylim([2.4,3.25])\n",
    "plt.plot([2.4,3.25], [2.4,3.25], 'k--', linewidth=2)\n",
    "plt.title('Target vs Predictions (Capacity)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
